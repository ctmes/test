{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctmes/test/blob/main/HANDLING_GEOSPATIAL_DATA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88qBxVs3EOJw"
      },
      "source": [
        "# IMPORTING GOOGLE EARTH (KML/KMZ FILES) - EARTHQUAKE DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1acrYpVQEOJz"
      },
      "source": [
        "<img src=\"https://github.com/Nouhailadr/HANDLING_GEOSPATIAL_DATA/blob/main/xs.png?raw=1\" alt=\"Image Alt Text\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL9Gn3RhEOJ0"
      },
      "source": [
        "First, let's install geopandas, a Python library for geospatial data manipulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0yc6AxlEOJ1",
        "outputId": "88185234-2ecb-40b1-c118-fe519c2662ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: fiona>=1.8.21 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.6)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.1.4)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.5)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (2024.7.4)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install geopandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdyV6x35EOJ3"
      },
      "source": [
        "Let's import the required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CKhfje7EOJ4"
      },
      "outputs": [],
      "source": [
        "import zipfile #We will use this library to extract data from KMZ file into KML one.\n",
        "import os #We will use it to manage file paths and check if files exist.\n",
        "import fiona #We will use it to parse and read the file in the KML format\n",
        "import pandas as pd\n",
        "import geopandas as gpd #We'll use it to read, process, and manipulate the KML file.\n",
        "from bs4 import BeautifulSoup #We will use it to parse HTML content embedded within one column of the KML file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhQLz-obEOJ4"
      },
      "source": [
        "# Importing Google Earth Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVMGU5v0EOJ4"
      },
      "source": [
        "First of all, we need to 'unzip' the KMZ file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dBChxhSEOJ5"
      },
      "outputs": [],
      "source": [
        "# Specify the path to our KMZ file\n",
        "kmz_file_path = \"C:/Users/HP/OneDrive/Documents/PROJECTS/Earthquake/hazards.kmz\"\n",
        "\n",
        "# Specify the directory where we want to extract the KML file (same directory as the KMZ file)\n",
        "extraction_dir = os.path.dirname(\"C:/Users/HP/OneDrive/Documents/PROJECTS/Earthquake/hazards.kmz\"  )\n",
        "\n",
        "# Open the KMZ file and extract its contents\n",
        "with zipfile.ZipFile(kmz_file_path, \"r\") as kmz:\n",
        "    kmz.extractall(extraction_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WB026oiEOJ6"
      },
      "source": [
        "We should want to enable KML support which is disabled by default, or else, we will face the unsupported Driver Error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysFMKIrdEOJ6"
      },
      "outputs": [],
      "source": [
        "fiona.drvsupport.supported_drivers['libkml'] = 'rw' # enable KML support which is disabled by default\n",
        "fiona.drvsupport.supported_drivers['LIBKML'] = 'rw'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJzoz2nLEOJ7"
      },
      "outputs": [],
      "source": [
        "#gdf = gpd.read_file(\"C:/Users/Earthquake/hazards/files/significantEarthquakes.kml\", driver='libkml')\n",
        "#gdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rprG6oBdEOJ7"
      },
      "source": [
        "Oups, the output is not right, only the names of the columns are displayed, no data in sight, maybe there is a problem with loading the whole dataset? let's try another way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvnURIPgEOJ7"
      },
      "outputs": [],
      "source": [
        "# Specify the path to the extracted KML file\n",
        "kml_file_path = \"C:/Users/HP/OneDrive/Documents/PROJECTS/Earthquake/hazards/files/\"\n",
        "fp_eq=kml_file_path+\"significantEarthquakes\"+'.kml'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D21u_pTAEOJ8"
      },
      "source": [
        "Next, we will use the fiona library to list all the layers within a KML file. Then, for each layer, we use geopandas to read and load the data from that specific layer within the KML file. Finally, we concatenate all these individual GeoDataFrames into a single GeoDataFrame called gdf, effectively merging the data from all KML layers into one consolidated dataset, sort of like collecting all the pieces of a puzzle into a single picture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I_Qd9a6EOJ8"
      },
      "outputs": [],
      "source": [
        "gdf_list = []\n",
        "for layer in fiona.listlayers(fp_eq):\n",
        "    gdf = gpd.read_file(fp_eq, driver='LIBKML', layer=layer)\n",
        "    gdf_list.append(gdf)\n",
        "\n",
        "gdf = gpd.GeoDataFrame(pd.concat(gdf_list, ignore_index=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHzbzc98EOJ8",
        "outputId": "179c3d07-36f6-43f5-9a6d-eba65c0f3fc4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>description</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "      <th>altitudeMode</th>\n",
              "      <th>tessellate</th>\n",
              "      <th>extrude</th>\n",
              "      <th>visibility</th>\n",
              "      <th>drawOrder</th>\n",
              "      <th>icon</th>\n",
              "      <th>geometry</th>\n",
              "      <th>snippet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2150/??/??</td>\n",
              "      <td>\\n        &lt;table width='300'&gt;\\n        &lt;tr&gt;\\n ...</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>POINT Z (35.50000 31.10000 0.00000)</td>\n",
              "      <td>JORDAN:  BAB-A-DARAA,AL-KARAK</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Name                                        description timestamp  \\\n",
              "0  -2150/??/??  \\n        <table width='300'>\\n        <tr>\\n ...       NaT   \n",
              "\n",
              "  begin end altitudeMode tessellate extrude visibility drawOrder icon  \\\n",
              "0   NaT NaT          NaN         -1       0          1       NaN  NaN   \n",
              "\n",
              "                              geometry                        snippet  \n",
              "0  POINT Z (35.50000 31.10000 0.00000)  JORDAN:  BAB-A-DARAA,AL-KARAK  "
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMPaMaFfEOJ8"
      },
      "source": [
        "Voila!\n",
        "What a satisfying moment (Yes because I don't know about you data scientists, but it was my first time working on this type of files, and it definitely took me some time to understand how it works)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rXjUSe-EOJ8"
      },
      "source": [
        "# Data Processing: Few examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3Bu5IFxEOJ8"
      },
      "source": [
        "First let's explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHWWkSmVEOJ8",
        "outputId": "e9255718-2adc-417a-92a9-b332c9c64f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows & columns in GeoDataFrame: (5884, 13)\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of rows & columns in GeoDataFrame:\", gdf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiwZy1sPEOJ9",
        "outputId": "44e07060-125a-4a81-9cff-767da589dc3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
            "RangeIndex: 5884 entries, 0 to 5883\n",
            "Data columns (total 13 columns):\n",
            " #   Column        Non-Null Count  Dtype         \n",
            "---  ------        --------------  -----         \n",
            " 0   Name          5884 non-null   object        \n",
            " 1   description   5884 non-null   object        \n",
            " 2   timestamp     0 non-null      datetime64[ns]\n",
            " 3   begin         0 non-null      datetime64[ns]\n",
            " 4   end           0 non-null      datetime64[ns]\n",
            " 5   altitudeMode  0 non-null      object        \n",
            " 6   tessellate    5884 non-null   object        \n",
            " 7   extrude       5884 non-null   object        \n",
            " 8   visibility    5884 non-null   object        \n",
            " 9   drawOrder     0 non-null      object        \n",
            " 10  icon          0 non-null      object        \n",
            " 11  geometry      5884 non-null   geometry      \n",
            " 12  snippet       5884 non-null   object        \n",
            "dtypes: datetime64[ns](3), geometry(1), object(9)\n",
            "memory usage: 597.7+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(gdf.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0x-ldJ_EOJ9",
        "outputId": "e4e2bebe-947f-40bb-d3fc-ca488445128b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name               0\n",
            "description        0\n",
            "timestamp       5884\n",
            "begin           5884\n",
            "end             5884\n",
            "altitudeMode    5884\n",
            "tessellate         0\n",
            "extrude            0\n",
            "visibility         0\n",
            "drawOrder       5884\n",
            "icon            5884\n",
            "geometry           0\n",
            "snippet            0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(gdf.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlFtfjZNEOJ9",
        "outputId": "651031df-aa5a-437b-ab99-a92540692438"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CHINA:  YUNNAN PROVINCE     68\n",
              "TURKEY                      49\n",
              "CHINA:  SICHUAN PROVINCE    44\n",
              "RUSSIA:  KURIL ISLANDS      39\n",
              "VANUATU ISLANDS             33\n",
              "Name: snippet, dtype: int64"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf['snippet'].value_counts().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2lvxw1bEOJ9",
        "outputId": "f3223176-6af6-4414-bfbe-c8010c5ff969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1954/09/09    4\n",
              "1901/08/09    4\n",
              "2006/06/03    3\n",
              "1989/03/10    3\n",
              "1750/??/??    3\n",
              "Name: EQ_Date, dtype: int64"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf = gdf.rename(columns={'Name': 'EQ_Date'})\n",
        "gdf['EQ_Date'].value_counts().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vam1PRECEOJ9",
        "outputId": "cbb7b6d2-0295-4e05-ac9e-cad652a2e7b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\\n        <table width='300'>\\n        <tr>\\n        <th>Location of Earthquake Effects:</th><td><nobr>JORDAN:  BAB-A-DARAA,AL-KARAK</nobr></td></tr>\\n        <tr><th>Earthquake Magnitude:</th><td>7.3</td></tr>\\n        <tr><th>Number of Deaths:</th><td>null</td></tr>\\n        <tr><th>Triggered a Tsunami?</th><td>No</td></tr>\\n        </table>\\n        <hr>\\n        <br><a href=\"https://www.ngdc.noaa.gov/nndc/struts/results?t=101650&s=13&d=229,26,13,12&nd=display&eq_0=1\">Get more details from NGDC Natural Hazards Website</a>\\n        <br>    1\n",
              "Name: description, dtype: int64"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf['description'].value_counts().head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2mBaduhEOJ-"
      },
      "outputs": [],
      "source": [
        "html_column = gdf['description']\n",
        "\n",
        "# Initialize empty lists to store extracted data\n",
        "EQ_location = []\n",
        "EQ_magnitude = []\n",
        "nb_deaths = []\n",
        "tsunami = []\n",
        "\n",
        "# Loop through the HTML strings in the column\n",
        "for html_string in html_column:\n",
        "    # Use BeautifulSoup to parse the HTML\n",
        "    soup = BeautifulSoup(html_string, 'html.parser')\n",
        "\n",
        "    # Extract data based on HTML structure and tags\n",
        "    # Example: Extracting location, magnitude, deaths, and tsunami information\n",
        "    table = soup.find('table')\n",
        "    rows = table.find_all('tr')\n",
        "\n",
        "    location = None\n",
        "    magnitude = None\n",
        "    deaths = None\n",
        "    tsunami_info = None\n",
        "\n",
        "    for row in rows:\n",
        "        header = row.find('th').text.strip()\n",
        "        data = row.find('td').text.strip()\n",
        "\n",
        "        if header == \"Location of Earthquake Effects:\":\n",
        "            location = data\n",
        "        elif header == \"Earthquake Magnitude:\":\n",
        "            magnitude = data\n",
        "        elif header == \"Number of Deaths:\":\n",
        "            deaths = data\n",
        "        elif header == \"Triggered a Tsunami?\":\n",
        "            tsunami_info = data\n",
        "\n",
        "    # Append the extracted data to the corresponding lists\n",
        "    EQ_location.append(location)\n",
        "    EQ_magnitude.append(magnitude)\n",
        "    nb_deaths.append(deaths)\n",
        "    tsunami.append(tsunami_info)\n",
        "\n",
        "# Create new columns in the GeoDataFrame\n",
        "gdf['EQ_location'] = EQ_location\n",
        "gdf['EQ_magnitude'] = EQ_magnitude\n",
        "gdf['Nb_deaths'] = nb_deaths\n",
        "gdf['Tsunami'] = tsunami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ6dZP1uEOJ-",
        "outputId": "083678ac-f4b1-42ce-cbfe-24baf48233cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0           JORDAN:  BAB-A-DARAA,AL-KARAK\n",
              "1                        TURKMENISTAN:  W\n",
              "2                          SYRIA:  UGARIT\n",
              "3       GREECE:  THERA ISLAND (SANTORINI)\n",
              "4                ISRAEL:  ARIHA (JERICHO)\n",
              "                      ...                \n",
              "5879                                CHILE\n",
              "5880                         FIJI ISLANDS\n",
              "5881                       INDIA:  AMBASA\n",
              "5882                         IRAN:  KHONJ\n",
              "5883                    ITALY:  FARINDOLA\n",
              "Name: EQ_location, Length: 5884, dtype: object"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf['EQ_location']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "66DfdDLuEOJ-"
      },
      "outputs": [],
      "source": [
        "cols_to_drop = ['description','snippet','visibility','tessellate','extrude','timestamp', 'begin', 'end','altitudeMode','drawOrder', 'icon']\n",
        "gdf.drop(columns=cols_to_drop, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_qhMXs_EOJ-",
        "outputId": "58bbe2ba-a7b6-46dd-80c2-b5e09dc84b59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "null                                4031\n",
              "Few (~1 to 50 people)                955\n",
              "Many (~101 to 1000 people)           412\n",
              "Very Many (~1001 or more people)     311\n",
              "Some (~51 to 100 people)             175\n",
              "Name: Nb_deaths, dtype: int64"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf['Nb_deaths'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0fsrL0mEOJ-",
        "outputId": "e4f486dd-8aa9-4cd4-a3c4-39ce154a32bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "unknown/None                        4031\n",
              "Few (~1 to 50 people)                955\n",
              "Many (~101 to 1000 people)           412\n",
              "Very Many (~1001 or more people)     311\n",
              "Some (~51 to 100 people)             175\n",
              "Name: Nb_deaths, dtype: int64"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf['Nb_deaths']=gdf['Nb_deaths'].replace('null', 'unknown/None')\n",
        "gdf['Nb_deaths'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "QZVLbnw-EOJ_",
        "outputId": "f1d338e8-d4bd-421d-89b6-d430f82de44e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EQ_Date</th>\n",
              "      <th>geometry</th>\n",
              "      <th>EQ_location</th>\n",
              "      <th>EQ_magnitude</th>\n",
              "      <th>Nb_deaths</th>\n",
              "      <th>Tsunami</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2150/??/??</td>\n",
              "      <td>POINT Z (35.50000 31.10000 0.00000)</td>\n",
              "      <td>JORDAN:  BAB-A-DARAA,AL-KARAK</td>\n",
              "      <td>7.3</td>\n",
              "      <td>unknown/None</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       EQ_Date                             geometry  \\\n",
              "0  -2150/??/??  POINT Z (35.50000 31.10000 0.00000)   \n",
              "\n",
              "                     EQ_location EQ_magnitude     Nb_deaths Tsunami  \n",
              "0  JORDAN:  BAB-A-DARAA,AL-KARAK          7.3  unknown/None      No  "
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5j8qnlMEOJ_"
      },
      "source": [
        "What a clean one! AHH satisfying, let's plot the earthquakes locations now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyzjPJViEOJ_"
      },
      "outputs": [],
      "source": [
        "gdf['Country'] = gdf['EQ_location'].str.split(':').str[0]\n",
        "gdf['Country'] = gdf['Country'].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcN_vWMUEOKA"
      },
      "outputs": [],
      "source": [
        "gdf['Region'] = gdf['EQ_location'].str.split(':').str[1]\n",
        "gdf['Region'] = gdf['Region'].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XsDw7eYEOKA"
      },
      "outputs": [],
      "source": [
        "gdf[['Year', 'Month', 'Day']] = gdf['EQ_Date'].str.split('/', expand=True).astype(str)\n",
        "\n",
        "gdf.drop(columns=['Day'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQxREyPJEOKA"
      },
      "outputs": [],
      "source": [
        "gdf['Month']=gdf['Month'].replace('??', 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-rQppN8EOKA",
        "outputId": "541c4863-63c9-4359-a6f8-2fc36052e83a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EQ_Date</th>\n",
              "      <th>geometry</th>\n",
              "      <th>EQ_location</th>\n",
              "      <th>EQ_magnitude</th>\n",
              "      <th>Nb_deaths</th>\n",
              "      <th>Tsunami</th>\n",
              "      <th>Country</th>\n",
              "      <th>Region</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5883</th>\n",
              "      <td>2017/01/18</td>\n",
              "      <td>POINT Z (13.24100 42.60100 0.00000)</td>\n",
              "      <td>ITALY:  FARINDOLA</td>\n",
              "      <td>5.7</td>\n",
              "      <td>Few (~1 to 50 people)</td>\n",
              "      <td>No</td>\n",
              "      <td>ITALY</td>\n",
              "      <td>FARINDOLA</td>\n",
              "      <td>2017</td>\n",
              "      <td>01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         EQ_Date                             geometry        EQ_location  \\\n",
              "5883  2017/01/18  POINT Z (13.24100 42.60100 0.00000)  ITALY:  FARINDOLA   \n",
              "\n",
              "     EQ_magnitude              Nb_deaths Tsunami Country     Region  Year  \\\n",
              "5883          5.7  Few (~1 to 50 people)      No   ITALY  FARINDOLA  2017   \n",
              "\n",
              "     Month  \n",
              "5883    01  "
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gdf.tail(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZrwJrALEOKA",
        "outputId": "1052d1c9-5329-4f37-9480-891232e8c1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GeoDataFrame has been exported to CSV: C:/Users/HP/OneDrive/Documents/PROJECTS/Earthquake/DATA/Earthquakes1.csv\n"
          ]
        }
      ],
      "source": [
        "#export to csv\n",
        "\n",
        "csv_file_path = \"C:/Users/HP/OneDrive/Documents/PROJECTS/Earthquake/DATA/Earthquakes1.csv\"\n",
        "gdf.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(\"GeoDataFrame has been exported to CSV:\", csv_file_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}